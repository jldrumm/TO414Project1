---
title: "Project1"
author: "Jasper Drumm, Leif Gullstad, Tommy Papesh, Aidan Hatzer, Jonah Cuenca"
date: "2022-10-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Cost Benefit Analysis

```{}
We will begin our report by starting with a cost-benefit analysis for the Telemarketing company. Because each call costs $1 for the company and each successful sale results in $6 of profit that means to at least break even 1 out of every 6 calls (16.67%) needs to be a successful sale. Therefore, our goal will be to create a prediction model which will result in at least 16.67% of the recommended calls being successful, thus ensuring the company breaks even, which is all they are concerned about according to knowledge given in class. 
```


## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```


## Starting With Clustering
```{r}
categories <- tele_norm #tele_norm is normalized using the normalize function we wrote 
categories$yyes <- NULL


categories_z <- as.data.frame(lapply(categories, scale)) # run on the normalized data so it is all numeric
set.seed(12345)
tele_clusters <- kmeans(categories_z, 5) 
tele_clusters$centers
tele_norm$cluster <- tele_clusters$cluster # put the cluster number with each tele record - leave clusters as numbers

aggregate(data = tele_norm, yyes ~ cluster, mean) # this gives the success rate
```

# Clustering Analysis

```{}
After doing the clustering analysis we have determined that no models should be created for clusters 3 and 4 because they have a success rate of 19.52% and 63.70% respectively. Based on the cost-benefit analysis done above both of these clusters would be profitable without any additional modeling work needing to be done, because as discussed above if we can get an accuracy of 16.67% or better than we will at least break even. 

Therefore we can now just make models for the 1st, 2nd, and 5th clusters to improve the accuracy when calling indidviduals in those clusters. 
```

# Create Cluster Variables
```{r}
cluster1_norm <- tele_norm[tele_norm$cluster == 1,]
cluster2_norm <- tele_norm[tele_norm$cluster == 2,]
cluster5_norm <- tele_norm[tele_norm$cluster == 5,]
str(cluster1_norm)
str(cluster2_norm)
str(cluster5_norm)
```

## Create the Majority Voting Scheme
```{r}
# Now create the majority voting data frame to be completed as we run the models later
#cluster1_majority_vote <- data.frame(matrix(ncol = 5, nrow = (nrow(cluster1_norm) - floor(0.3 * nrow(cluster1_norm)))))
#colnames(cluster1_majority_vote) <- c("actual", "ANN_predict", "KNN_predict", "LM_predict", "combined_predict")
#cluster2_majority_vote <- data.frame(matrix(ncol = 5, nrow = (nrow(cluster2_norm) - floor(0.3 * nrow(cluster2_norm)))))
#colnames(cluster2_majority_vote) <- c("actual", "ANN_predict", "KNN_predict", "LM_predict", "combined_predict")
#cluster5_majority_vote <- data.frame(matrix(ncol = 5, nrow = (nrow(cluster5_norm) - floor(0.3 * nrow(cluster5_norm)))))
#colnames(cluster5_majority_vote) <- c("actual", "ANN_predict", "KNN_predict", "LM_predict", "combined_predict")
```

> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.

## ANN function
```{r}

ANN_func <- function(cluster_norm) {
  # cluster_norm$cluster <- NULL
  set.seed(12345)
  cluster_sample <- sample(1:nrow(cluster_norm), floor(0.3 * nrow(cluster_norm))) # 30% size of cluster_norm to use for sample
  cluster_test <- cluster_norm[-cluster_sample,] # 70% for test
  cluster_train <- cluster_norm[cluster_sample,]
  
  library(caret)
  library(neuralnet)
  
  func_model <- neuralnet(formula = yyes~., data = cluster_train, hidden = 2)
  
  func_prediction <- predict(func_model, newdata = cluster_test, type = "response")
  func_prediction <- ifelse(func_prediction < 0.5, 0, 1)
  confusionMatrix(as.factor(cluster_test$yyes), as.factor(func_prediction))
  
  # return the func_prediction
  # return(as.factor(func_prediction))
}
```
## Logistics Model Function
```{r}
LM_func <- function(cluster_norm) {
  library(gmodels)
  set.seed(12345)
  cluster_sample <- sample(1:nrow(cluster_norm), floor(0.3 * nrow(cluster_norm))) # 30% size of cluster_norm to use for sample
  cluster_test <- cluster_norm[-cluster_sample,] # 70% for test
  cluster_train <- cluster_norm[cluster_sample,]
  
  cluster_model <- glm(yyes ~ ., data = cluster_train, family = "binomial")
  
  glm_Prediction <- predict(cluster_model, newdata = cluster_test, type = "response")
  glm_Prediction <- ifelse(glm_Prediction < 0.5, 0, 1)
  summary(glm_Prediction)

  CrossTable(x = cluster_test$yyes, y = glm_Prediction, prop.chisq = F)
  confusionMatrix(as.factor(cluster_test$yyes), as.factor(glm_Prediction))
  # return(as.factor(glm_Prediction))
}
```
## KNN Model Function
```{r}
KNN_func <- function(cluster_norm){

library(class)
library(caret)
library(gmodels)
set.seed(12345)

# just renamed indices variable
test_indices <- sample(1:nrow(cluster_norm), floor(0.3 * nrow(cluster_norm)))
cluster_test <- cluster_norm[-test_indices,] # 70% for test
cluster_train <- cluster_norm[test_indices,]

#labels must be the same length so get them from cluster1_norm
cluster_test_labels <- cluster_norm[-test_indices, "yyes"]
cluster_train_labels <- cluster_norm[test_indices, "yyes"]


#this cluster as a hwhole tends to have yyes = 0, so I set the k-val arbitrarily to a low number to be able to predict 1's - From Jake in OH
k_val <- 1

cluster_train$yyes <- NULL
cluster_test$yyes <- NULL

cluster_test_pred <- knn(train = cluster_train, test = cluster_test, cl = cluster_train_labels, k = k_val)

CrossTable(x = cluster_test_labels, y = cluster_test_pred, prop.chisq = FALSE)
confusionMatrix(as.factor(cluster_test_labels), as.factor(cluster_test_pred))
# return(as.factor(cluster_test_pred))
}
```


## Compare ANN, LM, KNN, and Majority Voting on Cluster 1
```{r, cache=T}
ANN_func(cluster_norm = cluster1_norm)
LM_func(cluster_norm = cluster1_norm)
KNN_func(cluster_norm = cluster1_norm)
#cluster1_majority_vote$combined_predict <- as.factor(ifelse(cluster1_majority_vote$ANN_predict == 1 && cluster1_majority_vote$LM_predict == 1, 1, ifelse(cluster1_majority_vote$ANN_predict == 1 && cluster1_majority_vote$KNN_predict == 1, 1, ifelse(cluster1_majority_vote$LM_predict == 1 && cluster1_majority_vote$KNN_predict == 1, 1, 0))))
```
## Compare ANN, LM, KNN, and Majority Voting on Cluster 2
```{r, cache=T}
ANN_func(cluster_norm = cluster2_norm)
LM_func(cluster_norm = cluster2_norm)
KNN_func(cluster_norm = cluster2_norm)
#cluster2_majority_vote$combined_predict <- as.factor(ifelse(cluster2_majority_vote$ANN_predict == 1 && cluster2_majority_vote$LM_predict == 1, 1, ifelse(cluster2_majority_vote$ANN_predict == 1 && cluster2_majority_vote$KNN_predict == 1, 1, ifelse(cluster2_majority_vote$LM_predict == 1 && cluster2_majority_vote$KNN_predict == 1, 1, 0))))
# print the majority scheme accuracy
#nrow(cluster2_majority_vote[cluster2_majority_vote$actual == cluster2_majority_vote$combined_predict]) / nrow(cluster2_majority_vote)
```

## Compare ANN, LM, KNN, and Majority Voting on Cluster 5
```{r, cache=T}
ANN_func(cluster_norm = cluster5_norm)
LM_func(cluster_norm = cluster5_norm)
KNN_func(cluster_norm = cluster5_norm)
#cluster5_majority_vote$combined_predict <- as.factor(ifelse(cluster5_majority_vote$ANN_predict == 1 && cluster5_majority_vote$LM_predict == 1, 1, ifelse(cluster5_majority_vote$ANN_predict == 1 && cluster5_majority_vote$KNN_predict == 1, 1, ifelse(cluster5_majority_vote$LM_predict == 1 && cluster5_majority_vote$KNN_predict == 1, 1, 0))))
```
## Final Analysis
```{}
With our analysis of ANN, KNN, and LM models, we strived to pick the model with the highest sensitivity and specificity. This is because high specificity helps predict which customers will subscribe to a term deposit based on similar characteristics to consumers who have purchased in the past, or in other words true positives. Additionally, high sensitivity helps us predict, which customers the banks should not try to sell to based on similar characteristics of consumers who hadn't purchased in the past, or in other words true negatives.

 

Banks are currently calling 41,188 people and are successful 11% of the time this means that their total costs are $41,188 ($1 per call) and their current Revenue is $31,715 ($7 in revenue per call ($6 in profit)). Therefore they have a negative profit margin of $9,473. As stated above the banks need to make a sale every 6 calls in order to become profitable, so this is what we will try to achieve with our models.

 

As stated in the earlier in the cluster cost-benefit analysis, banks should call everyone in clusters 3 and 4 because they are profitable and are above the breakeven threshold.

 

For clusters 1, 2, and 5 we believe that an LM model is best for banks to help make informed decisions, decide who to sell to, and improve their profitability.

All 3 clusters have very similar sensitivity for each model, with Cluster 1 having specificity between .964 and .965 for the ANN, LN and KNN models, cluster 2 has .943 for all models, and cluster 5 having between .936 and .937 for ANN and LN and .965 for KNN. However, the Logistic regression models have much higher Sensitivity than the ANN and KNN models across the board. Cluster 1 has an ANN sensitivity of .216, a KNN sensitivity of .072, and a LM sensitivity of .457. Cluster 2's ANN model has a sensitivity of .130, a KNN sensitivity of .077, and a LM model sensitivity of .5. Cluster 3’s ANN model has a sensitivity of .185, a KNN sensitivity of .093 and a LM sensitivity of .565. Because the LM models have much higher specifity ratings the banks will be able to predict true positives more accurately and will result in more profitability because they are spending less money on calling potential consumers who won't actually buy the service. One risk of utilizing the LM models over the ANN models is that the kappas are higher across the board for the LM models, meaning that the probability of randomness is higher. However, we believe this risk is mitigated by the fact that our specificity ratings for the LM models are so much more accurate.

 

After figuring out which models work best for determining who banks should target, we wanted to figure out what our new profit margins would be. Here are the following costs, revenue, and profits for each cluster:

 

Cluster 1: C: $35 R: $112, Profit: $77

Cluster 2: C: $4 R: $14, Profit: $10

Cluster 3: C: $11,994, R: $16,392, Profit: $4,398

Cluster 4: C: $1,518, R: $10,622, Profit: $9,104

Cluster 5: C: $23 R: $91, Profit $68

 

Total Profit after using our model: $13,657

 

Using our LN models and the data from clusters 3 and 4 we were able to help the banks achieve a profit of $13,657. Before using our models, the bank was operating at a loss of $9,473, so we helped them increase their profit by $23,130.

NOTE: A majority voting scheme was completed, however its implementation caused other backend issues to occur in RStudio throwing off the data in the other models, which is why it was left off of our final analysis. However, this code can be found in the comments for those curious about how it works, combining all of the other three models into one. 
```
